1. 2017-07-15
- Round 1:
    + Base model: 
        * SVC(decision_function_shape='ovo', probability=True, random_state=250)
        * Score: 0.2
    + Submision score: 1.64639
- Round 2:
    + Base model: 
        * XGBClassifier(n_estimators=500, max_depth=5, n_jobs = -1)
        * TfidfVectorizer()
        * Score: 0.65095285857572716
    + Submision score: 1.05601
- Round 3:
    + Base model: 
        * XGBClassifier(n_estimators=500, max_depth=5, n_jobs = -1)
        * TfidfVectorizer(min_df=5, max_features=2000, stop_words='english')
        * Score: 0.6268806419257773
    + Submision score: 0.94670
- Round 4:
    + Base model: 
        * XGBClassifier(n_estimators=500, max_depth=5, n_jobs = -1)
        * TfidfVectorizer(min_df=5, max_features=2000, stop_words=sw.words('english'), lowercase=True)
        * combine train data and eval data
        * tfidf time: 80 sec
        * model fit time: 299.95828080177307
        * Score: 0.633901705115
    + Submision score: 0.96945
- Round 5:
    + Base model: => NLTK
        * XGBClassifier(n_estimators=500, max_depth=5, n_jobs = -1)
        * TfidfVectorizer(min_df=5, max_features=2000, stop_words=sw.words('english'), tokenizer=tokenize_nltk, lowercase=True)
        * combine train data and eval data
        * tfidf time: 80 sec => 2946 sec
        * model fit time: 298 sec => 
        * Score: 0.629889669007 => 0.630892678034
    + Submision score: 1.02723 =>  0.99091   
- Round 6:
    + Base model: => spaCy
        * XGBClassifier(n_estimators=500, max_depth=5, n_jobs = -1)
        * TfidfVectorizer(min_df=5, max_features=2000, tokenizer=tokenize_spacy, lowercase=True)
        * combine train data and eval data
        * tfidf time: 5492.0656995773315
        * model fit time: 273.1438081264496 
        * Score: 0.636910732197
    + Submision score: 0.99091 =>  0.94846
2. 2017-07-17:     
- Round 7:
    + Base model: => gensim word2vec
        * XGBClassifier(n_estimators=500, max_depth=5, n_jobs = -1)
        * TfidfEmbeddingVectorizer(w2v)
        * combine train data and eval data
        * word2vec training time: 1625.335162639618
        * tfidf time: 2903.1875371932983
        * model fit time: 625.5327796936035
        * Score: 0.61183550652
    + Submision score: 1.06542
- Round 8:
    + Base model: 
        * XGBClassifier(n_estimators=500, max_depth=5, n_jobs = -1)
        * TfidfVectorizer(min_df=5, max_features=2000, stop_words=sw.words('english'), lowercase=True)
        * max_features = 2000
        * combine train data and eval data
        * Added Genes feature
        * tfidf time: 80 sec
        * model fit time: 285.72712326049805 
        * Score: 0.633901705115 => 0.642928786359
    + Submision score: 0.96945 => 0.95127  
- Round 9:    
    + Base model: = Round 8
        * max_features = 2000
        * Added Genes + Variation features
        * tfidf time: 80 sec
        * model fit time: 288.3759603500366 
        * Score: 0.642928786359 =>0.642928786359
    + Submision score: 0.95127 => 1.03381 
- Round 10:    
    + Base model: = Round 8
        * max_features = 16000
        * lsa_features = 2000      
        * tfidf time: 55.59057140350342 sec + 323.45097279548645 (reduction)
        * model fit time: 429.6618926525116 
        * Score: 0.616850551655 (lsa=500) => 0.618856569709 
    + Submision score: 0.95127 =>  0.97261 (lsa=500) => 1.00014     
3. 2017-07-19:
- Round 10:    
    + Base model: = 
        * CatBoostClassifier(iterations=500, depth=5, loss_function='Logloss', thread_count=W2V_N_THREADS,  verbose=True)
        * TfidfVectorizer(min_df=5, max_features=MAX_FEATURES, stop_words=STOPLIST,
            tokenizer=tokenizer, lowercase=True)
        * max_features = 16000
        * lsa_features = 2000      
        * tfidf time: 55.59057140350342 sec + 323.45097279548645 (reduction)
        * model fit time: 429.6618926525116 => Can not process sparse data
        * Score: 0.618856569709 => 
    + Submision score: 1.00014 =>    
    
    
